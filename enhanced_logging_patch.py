#!/usr/bin/env python3
"""
üîç Enhanced Logging Patch –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ Vector Search –ø—Ä–æ–±–ª–µ–º
"""

import re

def add_enhanced_logging():
    """–î–æ–¥–∞—î –¥–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è –≤ –∫—ñ–ª—å–∫–∞ —Ñ–∞–π–ª—ñ–≤"""
    
    # 1. Vector PDF Service - –¥–æ–¥–∞—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
    print("üîß Patching vector_pdf_service.py...")
    
    with open('backend/webhooks/vector_pdf_service.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –î–æ–¥–∞—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è –≤ _split_by_sections
    old_split_method = '''    def _split_by_sections(self, text: str) -> List[str]:
        """–†–æ–∑–¥—ñ–ª—è—î —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥—ñ—á–Ω—ñ —Å–µ–∫—Ü—ñ—ó"""
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω–∏ –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è Sample Replies
        patterns = [
            r'Example\\s*#\\d+',
            r'Inquiry information:',
            r'Response:',
            r'\\n\\n\\n+',  # –ú–Ω–æ–∂–∏–Ω–Ω—ñ –ø–µ—Ä–µ–Ω–æ—Å–∏ —Ä—è–¥–∫—ñ–≤
        ]
        
        sections = [text]
        
        for pattern in patterns:
            new_sections = []
            for section in sections:
                parts = re.split(f'({pattern})', section, flags=re.IGNORECASE)
                for part in parts:
                    if part.strip():
                        new_sections.append(part.strip())
            sections = new_sections
        
        return [s for s in sections if len(s.strip()) > 20]  # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ —Å–µ–∫—Ü—ñ—ó'''
    
    new_split_method = '''    def _split_by_sections(self, text: str) -> List[str]:
        """–†–æ–∑–¥—ñ–ª—è—î —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥—ñ—á–Ω—ñ —Å–µ–∫—Ü—ñ—ó"""
        
        logger.info(f"[VECTOR-PDF] üìÑ SPLITTING TEXT INTO SECTIONS:")
        logger.info(f"[VECTOR-PDF] Original text length: {len(text)} chars")
        logger.info(f"[VECTOR-PDF] Text preview (first 300 chars): {text[:300]}...")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω–∏ –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è Sample Replies
        patterns = [
            r'Example\\s*#\\d+',
            r'Inquiry information:',
            r'Response:',
            r'\\n\\n\\n+',  # –ú–Ω–æ–∂–∏–Ω–Ω—ñ –ø–µ—Ä–µ–Ω–æ—Å–∏ —Ä—è–¥–∫—ñ–≤
        ]
        
        sections = [text]
        
        for i, pattern in enumerate(patterns):
            logger.info(f"[VECTOR-PDF] üîÑ Applying pattern {i+1}: {pattern}")
            new_sections = []
            for section in sections:
                parts = re.split(f'({pattern})', section, flags=re.IGNORECASE)
                logger.info(f"[VECTOR-PDF]   Split into {len(parts)} parts")
                for j, part in enumerate(parts):
                    if part.strip():
                        logger.info(f"[VECTOR-PDF]     Part {j+1}: {len(part)} chars - '{part[:50]}...'")
                        new_sections.append(part.strip())
            sections = new_sections
            logger.info(f"[VECTOR-PDF] After pattern {i+1}: {len(sections)} sections")
        
        filtered_sections = [s for s in sections if len(s.strip()) > 20]
        logger.info(f"[VECTOR-PDF] üìã FINAL SECTIONS: {len(filtered_sections)} (after filtering < 20 chars)")
        
        for i, section in enumerate(filtered_sections):
            logger.info(f"[VECTOR-PDF] Section {i+1}: {len(section)} chars")
            logger.info(f"[VECTOR-PDF]   Content: {section[:100]}...")
        
        return filtered_sections'''
    
    content = content.replace(old_split_method, new_split_method)
    
    # –î–æ–¥–∞—Ç–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è –≤ _identify_chunk_type –ø–µ—Ä–µ–¥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—î—é
    old_identify = '''    def _identify_chunk_type(self, text: str) -> str:
        """üöÄ Enterprise Hybrid Classification: Rules ‚Üí Scoring ‚Üí Zero-shot ‚Üí ML"""
        try:
            # üéØ HYBRID APPROACH: Professional multi-stage classification
            from .hybrid_chunk_classifier import hybrid_classifier
            
            classification_result = hybrid_classifier.classify_chunk_hybrid(text)'''
    
    new_identify = '''    def _identify_chunk_type(self, text: str) -> str:
        """üöÄ Enterprise Hybrid Classification: Rules ‚Üí Scoring ‚Üí Zero-shot ‚Üí ML"""
        logger.info(f"[VECTOR-PDF] üéØ CLASSIFYING CHUNK:")
        logger.info(f"[VECTOR-PDF] Text length: {len(text)} chars")
        logger.info(f"[VECTOR-PDF] Text preview: {text[:150]}...")
        
        # –®–≤–∏–¥–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ—Å–Ω–æ–≤–Ω–∏—Ö –º–∞—Ä–∫–µ—Ä—ñ–≤ –ø–µ—Ä–µ–¥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—î—é
        text_lower = text.lower()
        quick_markers = {
            'inquiry_marker': 'inquiry information:' in text_lower,
            'response_marker': 'response:' in text_lower,
            'name_marker': 'name:' in text_lower,
            'good_afternoon': 'good afternoon' in text_lower,
            'good_morning': 'good morning' in text_lower,
            'thanks_reaching': 'thanks for reaching' in text_lower,
            'talk_soon': 'talk soon' in text_lower
        }
        logger.info(f"[VECTOR-PDF] Quick markers: {quick_markers}")
        
        try:
            # üéØ HYBRID APPROACH: Professional multi-stage classification
            from .hybrid_chunk_classifier import hybrid_classifier
            
            classification_result = hybrid_classifier.classify_chunk_hybrid(text)'''
    
    content = content.replace(old_identify, new_identify)
    
    with open('backend/webhooks/vector_pdf_service.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    # 2. AI Service - –¥–æ–¥–∞—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è vector search
    print("üîß Patching ai_service.py...")
    
    with open('backend/webhooks/ai_service.py', 'r', encoding='utf-8') as f:
        ai_content = f.read()
    
    # –ó–Ω–∞–π—Ç–∏ –º—ñ—Å—Ü–µ –¥–µ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è vector search –≤ generate_preview_message
    old_vector_call = '''                    similar_chunks = vector_search_service.search_similar_chunks(
                        query_text=custom_preview_text,
                        business_id=business.business_id,
                        location_id=None,
                        limit=search_limit,
                        similarity_threshold=similarity_threshold,
                        chunk_types=['response', 'example'] if not chunk_types else chunk_types  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç response chunks
                    )'''
    
    new_vector_call = '''                    logger.info(f"[AI-SERVICE] üîç CALLING VECTOR SEARCH:")
                    logger.info(f"[AI-SERVICE] Query text: {custom_preview_text[:100]}...")
                    logger.info(f"[AI-SERVICE] Business: {business.business_id}")
                    logger.info(f"[AI-SERVICE] Similarity threshold: {similarity_threshold}")
                    logger.info(f"[AI-SERVICE] Search limit: {search_limit}")
                    logger.info(f"[AI-SERVICE] Chunk types filter: {['response', 'example'] if not chunk_types else chunk_types}")
                    
                    similar_chunks = vector_search_service.search_similar_chunks(
                        query_text=custom_preview_text,
                        business_id=business.business_id,
                        location_id=None,
                        limit=search_limit,
                        similarity_threshold=similarity_threshold,
                        chunk_types=['response', 'example'] if not chunk_types else chunk_types  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç response chunks
                    )
                    
                    logger.info(f"[AI-SERVICE] üìä VECTOR SEARCH RESULTS:")
                    logger.info(f"[AI-SERVICE] Found chunks: {len(similar_chunks) if similar_chunks else 0}")'''
    
    ai_content = ai_content.replace(old_vector_call, new_vector_call)
    
    with open('backend/webhooks/ai_service.py', 'w', encoding='utf-8') as f:
        f.write(ai_content)
    
    print("‚úÖ Enhanced logging patches applied!")

if __name__ == '__main__':
    add_enhanced_logging()
