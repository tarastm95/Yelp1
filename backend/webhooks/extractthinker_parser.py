"""
üéØ ExtractThinker-Based Sample Replies Parser
Professional structured data extraction using AI + Pydantic contracts
"""

import logging
import re
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

# ExtractThinker imports with fallback
try:
    from extract_thinker import Extractor, ClassificationStrategy, ExtractionStrategy
    from extract_thinker.splitter import MarkdownSplitter
    EXTRACTTHINKER_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("[EXTRACTTHINKER] ‚úÖ ExtractThinker library available")
except ImportError as e:
    EXTRACTTHINKER_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning(f"[EXTRACTTHINKER] ‚ö†Ô∏è ExtractThinker not available: {e}")

from .extraction_contracts import CustomerInquiry, BusinessResponse, SampleReplyExample, SampleRepliesDocument

logger = logging.getLogger(__name__)


class SampleRepliesSplitter:
    """üîç Custom Splitter –¥–ª—è Sample Replies –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤"""
    
    @staticmethod
    def split_by_markers(text: str) -> List[Dict[str, str]]:
        """–†–æ–∑–¥—ñ–ª—è—î –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞ –º–∞—Ä–∫–µ—Ä–∞–º–∏ Inquiry/Response"""
        
        logger.info(f"[EXTRACTTHINKER-SPLITTER] üìÑ Splitting document by markers")
        logger.info(f"[EXTRACTTHINKER-SPLITTER] Document length: {len(text)} chars")
        
        # Patterns –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
        patterns = {
            'example': r'Example\s*#?\s*(\d+)',
            'inquiry': r'Inquiry\s+information:',
            'response': r'Response:'
        }
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –º–∞—Ä–∫–µ—Ä–∏ –∑ –ø–æ–∑–∏—Ü—ñ—è–º–∏
        markers = []
        
        for marker_type, pattern in patterns.items():
            for match in re.finditer(pattern, text, re.IGNORECASE):
                markers.append({
                    'type': marker_type,
                    'position': match.start(),
                    'text': match.group(),
                    'number': int(match.group(1)) if marker_type == 'example' and match.groups() else None
                })
        
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –ø–æ–∑–∏—Ü—ñ—î—é
        markers.sort(key=lambda x: x['position'])
        
        logger.info(f"[EXTRACTTHINKER-SPLITTER] Found {len(markers)} markers:")
        for marker in markers:
            logger.info(f"[EXTRACTTHINKER-SPLITTER]   {marker['type']}: pos {marker['position']} - '{marker['text']}'")
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ sections
        sections = []
        
        for i, marker in enumerate(markers):
            start_pos = marker['position']
            
            # –ö—ñ–Ω–µ—Ü—å —Å–µ–∫—Ü—ñ—ó = –ø–æ—á–∞—Ç–æ–∫ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ä–∞ –∞–±–æ –∫—ñ–Ω–µ—Ü—å —Ç–µ–∫—Å—Ç—É
            if i + 1 < len(markers):
                end_pos = markers[i + 1]['position']
            else:
                end_pos = len(text)
            
            section_text = text[start_pos:end_pos].strip()
            
            if len(section_text) > 20:  # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ —Å–µ–∫—Ü—ñ—ó
                sections.append({
                    'type': marker['type'],
                    'content': section_text,
                    'example_number': marker.get('number'),
                    'start_position': start_pos,
                    'end_position': end_pos
                })
                
                logger.info(f"[EXTRACTTHINKER-SPLITTER] Section {len(sections)}: {marker['type']} ({len(section_text)} chars)")
        
        logger.info(f"[EXTRACTTHINKER-SPLITTER] ‚úÖ Created {len(sections)} sections")
        return sections


class ExtractThinkerParser:
    """üß† AI-Powered Sample Replies Parser using ExtractThinker"""
    
    def __init__(self):
        self.extractor = None
        self.is_available = EXTRACTTHINKER_AVAILABLE
        self._init_extractor()
    
    def _init_extractor(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è ExtractThinker –∑ OpenAI"""
        
        if not self.is_available:
            logger.warning("[EXTRACTTHINKER] ‚ö†Ô∏è ExtractThinker not available - using fallback parsing")
            return
        
        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ OpenAI API key
            import os
            openai_api_key = os.getenv('OPENAI_API_KEY')
            
            if not openai_api_key:
                # Fallback to Django settings
                from .models import AISettings
                ai_settings = AISettings.objects.first()
                if ai_settings and ai_settings.openai_api_key:
                    openai_api_key = ai_settings.openai_api_key
            
            if not openai_api_key:
                raise ValueError("No OpenAI API key found")
            
            # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ ExtractThinker
            self.extractor = Extractor(
                api_key=openai_api_key,
                model_name="gpt-4o-mini",  # –ï–∫–æ–Ω–æ–º–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è extraction
                classification_strategy=ClassificationStrategy.ZERO_SHOT,
                extraction_strategy=ExtractionStrategy.LLM
            )
            
            logger.info("[EXTRACTTHINKER] ‚úÖ ExtractThinker initialized successfully")
            
        except Exception as e:
            logger.error(f"[EXTRACTTHINKER] ‚ùå Failed to initialize: {e}")
            self.extractor = None
            self.is_available = False
    
    def parse_sample_replies_document(self, text: str) -> Optional[SampleRepliesDocument]:
        """
        üéØ –ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥—É Sample Replies –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        1. –†–æ–∑–¥—ñ–ª—è—î –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞ –º–∞—Ä–∫–µ—Ä–∞–º–∏
        2. –í–∏—Ç—è–≥—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ –∑ –∫–æ–∂–Ω–æ—ó —Å–µ–∫—Ü—ñ—ó
        3. –ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω—ñ—Å—Ç—é —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
        """
        
        logger.info(f"[EXTRACTTHINKER] üöÄ PARSING SAMPLE REPLIES DOCUMENT")
        logger.info(f"[EXTRACTTHINKER] Document length: {len(text)} chars")
        
        if not self.is_available:
            logger.warning("[EXTRACTTHINKER] ‚ö†Ô∏è ExtractThinker not available, using fallback")
            return self._fallback_parsing(text)
        
        try:
            # 1. –†–æ–∑–¥—ñ–ª—è—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å–µ–∫—Ü—ñ—ó
            sections = SampleRepliesSplitter.split_by_markers(text)
            
            if not sections:
                logger.warning("[EXTRACTTHINKER] ‚ö†Ô∏è No sections found, using fallback")
                return self._fallback_parsing(text)
            
            # 2. –ì—Ä—É–ø—É—î–º–æ —Å–µ–∫—Ü—ñ—ó –≤ –ø—Ä–∏–∫–ª–∞–¥–∏ (inquiry + response –ø–∞—Ä–∏)
            examples = self._group_sections_into_examples(sections)
            
            # 3. –í–∏—Ç—è–≥—É—î–º–æ structured data –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—É
            structured_examples = []
            
            for example_data in examples:
                try:
                    structured_example = self._extract_example_data(example_data)
                    if structured_example:
                        structured_examples.append(structured_example)
                        
                except Exception as e:
                    logger.warning(f"[EXTRACTTHINKER] ‚ö†Ô∏è Failed to extract example {example_data.get('example_number', '?')}: {e}")
            
            # 4. –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ–≤–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
            document = SampleRepliesDocument(
                document_title=self._extract_document_title(text),
                business_name=self._extract_business_name(text),
                examples=structured_examples,
                total_examples=len(structured_examples),
                extraction_quality=self._assess_extraction_quality(structured_examples),
                raw_document_text=text
            )
            
            logger.info(f"[EXTRACTTHINKER] ‚úÖ EXTRACTION SUCCESS:")
            logger.info(f"[EXTRACTTHINKER]   Examples found: {len(structured_examples)}")
            logger.info(f"[EXTRACTTHINKER]   Quality: {document.extraction_quality}")
            logger.info(f"[EXTRACTTHINKER]   Business: {document.business_name}")
            
            return document
            
        except Exception as e:
            logger.error(f"[EXTRACTTHINKER] ‚ùå Extraction failed: {e}")
            return self._fallback_parsing(text)
    
    def _group_sections_into_examples(self, sections: List[Dict]) -> List[Dict]:
        """–ì—Ä—É–ø—É—î inquiry —Ç–∞ response —Å–µ–∫—Ü—ñ—ó –≤ –ø—Ä–∏–∫–ª–∞–¥–∏"""
        
        logger.info(f"[EXTRACTTHINKER] üîó Grouping {len(sections)} sections into examples")
        
        examples = []
        current_example = {}
        current_example_number = None
        
        for section in sections:
            section_type = section['type']
            
            if section_type == 'example':
                # –ù–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥ –ø–æ—á–∞–≤—Å—è
                if current_example:
                    examples.append(current_example)
                
                current_example = {
                    'example_number': section.get('example_number'),
                    'sections': []
                }
                current_example_number = section.get('example_number')
                
            # –î–æ–¥–∞—î–º–æ —Å–µ–∫—Ü—ñ—é –¥–æ –ø–æ—Ç–æ—á–Ω–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—É
            current_example.setdefault('sections', []).append(section)
        
        # –î–æ–¥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –ø—Ä–∏–∫–ª–∞–¥
        if current_example:
            examples.append(current_example)
        
        logger.info(f"[EXTRACTTHINKER] ‚úÖ Grouped into {len(examples)} examples")
        
        for i, example in enumerate(examples):
            section_types = [s['type'] for s in example['sections']]
            logger.info(f"[EXTRACTTHINKER]   Example {example.get('example_number', i+1)}: {section_types}")
        
        return examples
    
    def _extract_example_data(self, example_data: Dict) -> Optional[SampleReplyExample]:
        """–í–∏—Ç—è–≥—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ –∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—É"""
        
        example_num = example_data.get('example_number', 0)
        sections = example_data.get('sections', [])
        
        logger.info(f"[EXTRACTTHINKER] üîç Extracting data from example {example_num}")
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ inquiry —Ç–∞ response —Å–µ–∫—Ü—ñ—ó
        inquiry_section = None
        response_section = None
        
        for section in sections:
            if section['type'] == 'inquiry':
                inquiry_section = section
            elif section['type'] == 'response':
                response_section = section
        
        if not inquiry_section or not response_section:
            logger.warning(f"[EXTRACTTHINKER] ‚ö†Ô∏è Example {example_num}: Missing inquiry or response section")
            return None
        
        # –í–∏—Ç—è–≥—É—î–º–æ structured data –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é ExtractThinker
        try:
            # Extract Inquiry
            inquiry_text = inquiry_section['content']
            logger.info(f"[EXTRACTTHINKER] üîç Extracting inquiry from: {inquiry_text[:100]}...")
            
            inquiry_result = self.extractor.extract(
                text=inquiry_text,
                schema=CustomerInquiry,
                classification_strategy=ClassificationStrategy.ZERO_SHOT
            )
            
            if not inquiry_result or not inquiry_result.data:
                logger.warning(f"[EXTRACTTHINKER] ‚ö†Ô∏è Failed to extract inquiry data")
                return None
            
            # Extract Response
            response_text = response_section['content']
            logger.info(f"[EXTRACTTHINKER] üîç Extracting response from: {response_text[:100]}...")
            
            response_result = self.extractor.extract(
                text=response_text,
                schema=BusinessResponse,
                classification_strategy=ClassificationStrategy.ZERO_SHOT
            )
            
            if not response_result or not response_result.data:
                logger.warning(f"[EXTRACTTHINKER] ‚ö†Ô∏è Failed to extract response data")
                return None
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ structured example
            structured_example = SampleReplyExample(
                example_number=example_num,
                inquiry=inquiry_result.data,
                response=response_result.data,
                context_match_score=self._calculate_context_match(inquiry_result.data, response_result.data)
            )
            
            logger.info(f"[EXTRACTTHINKER] ‚úÖ Example {example_num} extracted successfully")
            logger.info(f"[EXTRACTTHINKER]   Customer: {inquiry_result.data.customer_name}")
            logger.info(f"[EXTRACTTHINKER]   Service: {inquiry_result.data.service_type}")
            logger.info(f"[EXTRACTTHINKER]   Response tone: {response_result.data.tone}")
            
            return structured_example
            
        except Exception as e:
            logger.error(f"[EXTRACTTHINKER] ‚ùå Failed to extract example {example_num}: {e}")
            return None
    
    def _calculate_context_match(self, inquiry: CustomerInquiry, response: BusinessResponse) -> float:
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î –Ω–∞—Å–∫—ñ–ª—å–∫–∏ inquiry —Ç–∞ response –ø—ñ–¥—Ö–æ–¥—è—Ç—å –æ–¥–∏–Ω –æ–¥–Ω–æ–º—É"""
        
        match_score = 0.0
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —ñ–º'—è –∫–ª—ñ—î–Ω—Ç–∞ –∑–≥–∞–¥—É—î—Ç—å—Å—è –≤ response
        if inquiry.customer_name and response.customer_name_mentioned:
            if inquiry.customer_name.lower() in response.customer_name_mentioned.lower():
                match_score += 0.3
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ service type –∑–≥–∞–¥—É—î—Ç—å—Å—è –≤ response
        if inquiry.service_type and response.service_acknowledgment:
            service_words = inquiry.service_type.lower().split()
            acknowledgment_lower = response.service_acknowledgment.lower()
            if any(word in acknowledgment_lower for word in service_words):
                match_score += 0.3
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω—ñ—Å—Ç—å response
        if response.greeting_type and response.closing_phrase:
            match_score += 0.2
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è –≤ response (engagement)
        if response.questions_asked and len(response.questions_asked) > 0:
            match_score += 0.2
        
        return min(match_score, 1.0)  # Cap at 1.0
    
    def _extract_document_title(self, text: str) -> Optional[str]:
        """–í–∏—Ç—è–≥—É—î –Ω–∞–∑–≤—É –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        
        lines = text.split('\n')[:5]  # –ü–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤
        
        for line in lines:
            line = line.strip()
            if len(line) > 10 and 'sample replies' in line.lower():
                return line
        
        return None
    
    def _extract_business_name(self, text: str) -> Optional[str]:
        """–í–∏—Ç—è–≥—É—î –Ω–∞–∑–≤—É –±—ñ–∑–Ω–µ—Å—É"""
        
        # –®—É–∫–∞—î–º–æ –≤ –Ω–∞–∑–≤—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title_match = re.search(r'Sample Replies\s*[‚Äì-]\s*(.+)', text, re.IGNORECASE)
        if title_match:
            business_name = title_match.group(1).strip()
            # –í–∏–¥–∞–ª—è—î–º–æ "Roofing" —è–∫—â–æ –≤ –∫—ñ–Ω—Ü—ñ
            business_name = re.sub(r'\s*Roofing\s*$', '', business_name, re.IGNORECASE)
            return business_name
        
        return None
    
    def _assess_extraction_quality(self, examples: List[SampleReplyExample]) -> str:
        """–û—Ü—ñ–Ω—é—î —è–∫—ñ—Å—Ç—å extraction"""
        
        if not examples:
            return "poor"
        
        # –†–∞—Ö—É—î–º–æ —Å–∫—ñ–ª—å–∫–∏ examples –º–∞—é—Ç—å –ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ
        complete_examples = 0
        
        for example in examples:
            inquiry = example.inquiry
            response = example.response
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ–≤–Ω–æ—Ç–∏ inquiry
            inquiry_complete = bool(
                inquiry.customer_name and 
                inquiry.service_type and 
                inquiry.location
            )
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ–≤–Ω–æ—Ç–∏ response
            response_complete = bool(
                response.greeting_type and 
                response.acknowledgment_phrase and 
                response.closing_phrase
            )
            
            if inquiry_complete and response_complete:
                complete_examples += 1
        
        completion_rate = complete_examples / len(examples)
        
        if completion_rate >= 0.8:
            return "excellent"
        elif completion_rate >= 0.6:
            return "good"
        elif completion_rate >= 0.4:
            return "fair"
        else:
            return "poor"
    
    def _fallback_parsing(self, text: str) -> SampleRepliesDocument:
        """Fallback parsing –±–µ–∑ ExtractThinker"""
        
        logger.warning("[EXTRACTTHINKER] üîÑ Using fallback parsing (no AI extraction)")
        
        # –ü—Ä–æ—Å—Ç–∏–π regex-based fallback
        sections = SampleRepliesSplitter.split_by_markers(text)
        
        examples = []
        current_inquiry = None
        current_response = None
        
        for section in sections:
            if section['type'] == 'inquiry':
                current_inquiry = section['content']
            elif section['type'] == 'response' and current_inquiry:
                current_response = section['content']
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ—Å—Ç–∏–π –ø—Ä–∏–∫–ª–∞–¥ –±–µ–∑ AI extraction
                simple_example = SampleReplyExample(
                    example_number=section.get('example_number', len(examples) + 1),
                    inquiry=CustomerInquiry(
                        raw_text=current_inquiry,
                        customer_name=self._simple_extract_name(current_inquiry),
                        service_type=self._simple_extract_service(current_inquiry)
                    ),
                    response=BusinessResponse(
                        raw_text=current_response,
                        greeting_type=self._simple_extract_greeting(current_response),
                        tone=self._simple_extract_tone(current_response)
                    )
                )
                
                examples.append(simple_example)
                current_inquiry = None
                current_response = None
        
        return SampleRepliesDocument(
            document_title=self._extract_document_title(text),
            business_name=self._extract_business_name(text),
            examples=examples,
            total_examples=len(examples),
            extraction_quality="fair",  # Fallback –∑–∞–≤–∂–¥–∏ "fair"
            raw_document_text=text
        )
    
    def _simple_extract_name(self, text: str) -> Optional[str]:
        """–ü—Ä–æ—Å—Ç–∏–π regex –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —ñ–º–µ–Ω—ñ"""
        match = re.search(r'Name:\s*([A-Z][a-z]+\s*[A-Z]?\.?)', text)
        return match.group(1).strip() if match else None
    
    def _simple_extract_service(self, text: str) -> Optional[str]:
        """–ü—Ä–æ—Å—Ç–∏–π regex –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–∏–ø—É –ø–æ—Å–ª—É–≥–∏"""
        lines = text.split('\n')
        for line in lines[1:3]:  # 2-3 —Ä—è–¥–∫–∏ –ø—ñ—Å–ª—è Name
            line = line.strip()
            if line and not line.startswith(('Lead created:', 'What kind of')):
                return line
        return None
    
    def _simple_extract_greeting(self, text: str) -> Optional[str]:
        """–ü—Ä–æ—Å—Ç–∏–π regex –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–∏–ø—É –ø—Ä–∏–≤—ñ—Ç–∞–Ω–Ω—è"""
        text_lower = text.lower()
        if 'good afternoon' in text_lower:
            return 'Good afternoon'
        elif 'good morning' in text_lower:
            return 'Good morning' 
        elif 'hello' in text_lower:
            return 'Hello'
        return None
    
    def _simple_extract_tone(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–æ–Ω—É"""
        text_lower = text.lower()
        
        if any(casual in text_lower for casual in ['thanks so much', "we'd be glad", 'talk soon']):
            return 'friendly'
        elif any(formal in text_lower for formal in ['we appreciate', 'thank you for your inquiry']):
            return 'formal'
        else:
            return 'professional'


# –ì–ª–æ–±–∞–ª—å–Ω–∞ instance
extractthinker_parser = ExtractThinkerParser()
