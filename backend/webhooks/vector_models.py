"""
üîç Vector Models for Sample Replies with pgvector
–ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —Ç–∞ —á–∞–Ω–∫—ñ–≤ –∑ –µ–º–±–µ–¥—ñ–Ω–≥–∞–º–∏ OpenAI –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É
"""

from django.db import models
from pgvector.django import VectorField
from .models import YelpBusiness
import json

class VectorDocument(models.Model):
    """PDF –¥–æ–∫—É–º–µ–Ω—Ç –∑ Sample Replies –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É"""
    
    # Business association
    business_id = models.CharField(
        max_length=128, 
        db_index=True,
        help_text="Yelp business ID –¥–ª—è —è–∫–æ–≥–æ —Ü–µ–π –¥–æ–∫—É–º–µ–Ω—Ç"
    )
    location_id = models.CharField(
        max_length=128, 
        blank=True, 
        null=True,
        db_index=True,
        help_text="–û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π location ID –¥–ª—è –º—É–ª—å—Ç–∏-–ª–æ–∫–∞—Ü—ñ–π–Ω–∏—Ö –±—ñ–∑–Ω–µ—Å—ñ–≤"
    )
    
    # Document metadata
    filename = models.CharField(max_length=255)
    file_hash = models.CharField(
        max_length=64, 
        unique=True, 
        help_text="SHA-256 —Ö–µ—à –≤–º—ñ—Å—Ç—É —Ñ–∞–π–ª—É –¥–ª—è –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—ó"
    )
    file_size = models.PositiveIntegerField(help_text="–†–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É –≤ –±–∞–π—Ç–∞—Ö")
    
    # Processing statistics
    page_count = models.PositiveIntegerField(default=0)
    chunk_count = models.PositiveIntegerField(default=0)
    total_tokens = models.PositiveIntegerField(default=0)
    
    # Processing status
    processing_status = models.CharField(
        max_length=20,
        choices=[
            ('processing', 'Processing'),
            ('completed', 'Completed'),
            ('error', 'Error'),
        ],
        default='processing'
    )
    error_message = models.TextField(blank=True, null=True)
    
    # Embedding model info
    embedding_model = models.CharField(
        max_length=50,
        default='text-embedding-3-small',
        help_text="OpenAI –º–æ–¥–µ–ª—å –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∞ –¥–ª—è –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤"
    )
    embedding_dimensions = models.PositiveIntegerField(
        default=1536,
        help_text="–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ñ–≤ –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤"
    )
    
    # Metadata
    metadata = models.JSONField(
        default=dict,
        help_text="–î–æ–¥–∞—Ç–∫–æ–≤—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ –ø—Ä–æ –æ–±—Ä–æ–±–∫—É —Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"
    )
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        db_table = 'webhooks_vectordocument'
        indexes = [
            models.Index(fields=['business_id', '-created_at']),
            models.Index(fields=['business_id', 'location_id']),
            models.Index(fields=['processing_status']),
            models.Index(fields=['file_hash']),
        ]
        constraints = [
            models.UniqueConstraint(
                fields=['business_id', 'location_id', 'file_hash'],
                name='unique_vector_business_location_file'
            )
        ]
    
    def __str__(self):
        location_part = f" (Location: {self.location_id})" if self.location_id else ""
        return f"Vector Doc: {self.filename} - {self.business_id}{location_part}"
    
    @property
    def is_ready_for_search(self) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ –¥–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É"""
        return (
            self.processing_status == 'completed' and 
            self.chunk_count > 0
        )


class VectorChunk(models.Model):
    """–°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π —á–∞–Ω–∫ —Ç–µ–∫—Å—Ç—É –∑ –≤–µ–∫—Ç–æ—Ä–Ω–∏–º –µ–º–±–µ–¥—ñ–Ω–≥–æ–º –¥–ª—è –ø–æ—à—É–∫—É"""
    
    # Document reference
    document = models.ForeignKey(
        VectorDocument,
        on_delete=models.CASCADE,
        related_name='chunks',
        help_text="–î–æ–∫—É–º–µ–Ω—Ç –¥–æ —è–∫–æ–≥–æ –Ω–∞–ª–µ–∂–∏—Ç—å —Ü–µ–π —á–∞–Ω–∫"
    )
    
    # Content information  
    content = models.TextField(help_text="–¢–µ–∫—Å—Ç–æ–≤–∏–π –≤–º—ñ—Å—Ç —á–∞–Ω–∫—É")
    page_number = models.PositiveIntegerField(help_text="–ù–æ–º–µ—Ä —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –¥–∂–µ—Ä–µ–ª–∞")
    chunk_index = models.PositiveIntegerField(help_text="–ü–æ—Ä—è–¥–æ–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ñ")
    token_count = models.PositiveIntegerField(help_text="–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤ —É —á–∞–Ω–∫—É")
    
    # Vector embedding (1536 dimensions for text-embedding-3-small)
    embedding = VectorField(
        dimensions=1536,
        help_text="OpenAI text-embedding-3-small –≤–µ–∫—Ç–æ—Ä (1536 —Ä–æ–∑–º—ñ—Ä—ñ–≤)"
    )
    
    # Semantic metadata
    chunk_type = models.CharField(
        max_length=20,
        choices=[
            ('inquiry', 'Customer Inquiry'),
            ('response', 'Business Response'),
            ('example', 'Complete Example'),
            ('general', 'General Content'),
        ],
        default='general',
        help_text="–¢–∏–ø —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É"
    )
    
    # Additional metadata
    metadata = models.JSONField(
        default=dict,
        help_text="–ú–µ—Ç–∞–¥–∞–Ω—ñ —á–∞–Ω–∫—É: has_customer_name, has_service_type, etc."
    )
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        db_table = 'webhooks_vectorchunk'
        indexes = [
            models.Index(fields=['document', 'chunk_index']),
            models.Index(fields=['chunk_type']),
            models.Index(fields=['page_number']),
            # Vector similarity index –±—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –≤ –º—ñ–≥—Ä–∞—Ü—ñ—ó
        ]
        constraints = [
            models.UniqueConstraint(
                fields=['document', 'chunk_index'],
                name='unique_vector_document_chunk_index'
            )
        ]
    
    def __str__(self):
        return f"Vector Chunk {self.chunk_index} from {self.document.filename} (page {self.page_number})"
    
    def get_preview(self, max_length: int = 100) -> str:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø—Ä–µ–≤ º—é –≤–º—ñ—Å—Ç—É —á–∞–Ω–∫—É"""
        if len(self.content) <= max_length:
            return self.content
        return self.content[:max_length] + "..."
    
    @property
    def similarity_search_ready(self) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —á–∞–Ω–∫ –≥–æ—Ç–æ–≤–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É"""
        return bool(self.embedding)
    
    def calculate_similarity(self, query_embedding: list) -> float:
        """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Å–∏–Ω—É—Å–Ω–æ—ó —Å—Ö–æ–∂–æ—Å—Ç—ñ –∑ query embedding"""
        if not self.embedding:
            return 0.0
        
        # –¶–µ –±—É–¥–µ –≤–∏–∫–æ–Ω–∞–Ω–æ —á–µ—Ä–µ–∑ raw SQL –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É –ø–æ—à—É–∫—É
        # –¢—É—Ç –ø—Ä–æ—Å—Ç–æ placeholder
        return 0.0
