"""
üîç Minimal Working Vector PDF Service
Simplified version without broken code
"""

import logging
import re
import hashlib
from typing import Optional, List, Dict, Tuple
from dataclasses import dataclass
from django.db import transaction
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
import openai
import os

# PDF processing imports
try:
    import fitz  # PyMuPDF
    import tiktoken
    import numpy as np
    PDF_PROCESSING_AVAILABLE = True
except ImportError:
    PDF_PROCESSING_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class DocumentChunk:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è—î —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π —á–∞–Ω–∫ –¥–æ–∫—É–º–µ–Ω—Ç—É"""
    content: str
    page_number: int
    chunk_index: int
    token_count: int
    chunk_type: str
    metadata: Dict

class VectorPDFService:
    """üîç –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –≤–µ–∫—Ç–æ—Ä–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –¥–ª—è –æ–±—Ä–æ–±–∫–∏ PDF"""
    
    def __init__(self):
        self.openai_client = None
        self.encoding = None
        self._init_openai()
        self._init_tokenizer()
    
    def _init_openai(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è OpenAI –∫–ª—ñ—î–Ω—Ç–∞"""
        try:
            from .models import AISettings
            
            openai_api_key = os.getenv('OPENAI_API_KEY')
            
            if not openai_api_key:
                ai_settings = AISettings.objects.first()
                if ai_settings and ai_settings.openai_api_key:
                    openai_api_key = ai_settings.openai_api_key
            
            if openai_api_key:
                self.openai_client = openai.OpenAI(api_key=openai_api_key)
                logger.info("[VECTOR-PDF] OpenAI client initialized successfully")
            else:
                logger.error("[VECTOR-PDF] No OpenAI API key found")
                
        except Exception as e:
            logger.error(f"[VECTOR-PDF] Failed to initialize OpenAI client: {e}")
    
    def _init_tokenizer(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è tiktoken –µ–Ω–∫–æ–¥–µ—Ä–∞"""
        try:
            if not PDF_PROCESSING_AVAILABLE:
                logger.warning("[VECTOR-PDF] Tiktoken not available")
                return
                
            self.encoding = tiktoken.encoding_for_model("text-embedding-3-small")
            logger.info("[VECTOR-PDF] Tiktoken encoder initialized")
            
        except Exception as e:
            logger.error(f"[VECTOR-PDF] Failed to initialize tokenizer: {e}")
    
    def extract_text_from_pdf_bytes(self, pdf_bytes: bytes, filename: str) -> Dict:
        """üìÑ Simple PDF extraction using PyMuPDF"""
        
        logger.info(f"[VECTOR-PDF] üìÑ Extracting text from PDF: {filename}")
        
        if not PDF_PROCESSING_AVAILABLE:
            raise ValueError("PDF processing libraries not available.")
        
        try:
            doc = fitz.open("pdf", pdf_bytes)
            pages_data = []
            all_text_parts = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                
                if text.strip():
                    pages_data.append({
                        'page_number': page_num + 1,
                        'text': text,
                        'char_count': len(text)
                    })
                    all_text_parts.append(text)
            
            doc.close()
            all_text = "\n\n".join(all_text_parts)
            
            logger.info(f"[VECTOR-PDF] Extracted {len(all_text)} chars from {len(pages_data)} pages")
            
            return {
                'success': True,
                'text': all_text,
                'pages': pages_data,
                'parser_used': 'pymupdf'
            }
            
        except Exception as e:
            logger.error(f"[VECTOR-PDF] PDF extraction error: {e}")
            return {
                'success': False,
                'text': '',
                'pages': [],
                'errors': [str(e)]
            }
    
    def create_semantic_chunks(self, text: str, max_tokens: int = 800) -> List[DocumentChunk]:
        """–°—Ç–≤–æ—Ä—é—î —Å–µ–º–∞–Ω—Ç–∏—á–Ω—ñ —á–∞–Ω–∫–∏ –∑ —Ç–µ–∫—Å—Ç—É"""
        
        logger.info(f"[VECTOR-PDF] Creating semantic chunks...")
        logger.info(f"[VECTOR-PDF] Text length: {len(text)} chars")
        
        # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Å–µ–∫—Ü—ñ—ó
        sections = self._split_by_sections(text)
        
        chunks = []
        chunk_index = 0
        
        for section in sections:
            if not section.strip() or len(section) < 20:
                continue
            
            token_count = self._count_tokens(section)
            chunk_type = self._identify_chunk_type(section)
            
            logger.info(f"[VECTOR-PDF] üß© CHUNK #{chunk_index}:")
            logger.info(f"[VECTOR-PDF]   Type: {chunk_type}")
            logger.info(f"[VECTOR-PDF]   Length: {len(section)} chars")
            logger.info(f"[VECTOR-PDF]   Preview: {section[:100]}...")
            
            chunks.append(DocumentChunk(
                content=section.strip(),
                page_number=1,
                chunk_index=chunk_index,
                token_count=token_count,
                chunk_type=chunk_type,
                metadata={
                    'section_length': len(section),
                    'has_inquiry': 'inquiry information:' in section.lower(),
                    'has_response': 'response:' in section.lower(),
                    'has_customer_name': bool(re.search(r'name:\s*\w+', section, re.IGNORECASE)),
                }
            ))
            chunk_index += 1
        
        logger.info(f"[VECTOR-PDF] Created {len(chunks)} chunks")
        return chunks
    
    def _split_by_sections(self, text: str) -> List[str]:
        """–†–æ–∑–¥—ñ–ª—è—î —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥—ñ—á–Ω—ñ —Å–µ–∫—Ü—ñ—ó"""
        
        logger.info(f"[VECTOR-PDF] Splitting text into sections...")
        
        patterns = [
            r'Example\s*#\d+',
            r'Inquiry information:',
            r'Response:',
            r'\n\n\n+',
        ]
        
        sections = [text]
        
        for pattern in patterns:
            new_sections = []
            for section in sections:
                parts = re.split(f'({pattern})', section, flags=re.IGNORECASE)
                for part in parts:
                    if part.strip():
                        new_sections.append(part.strip())
            sections = new_sections
        
        return [s for s in sections if len(s.strip()) > 20]
    
    def _identify_chunk_type(self, text: str) -> str:
        """–í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø —á–∞–Ω–∫–∞ –∑ enhanced logic"""
        
        text_lower = text.lower().strip()
        
        # Explicit markers
        if 'inquiry information:' in text_lower:
            return 'inquiry'
        elif 'response:' in text_lower:
            return 'response'
        
        # Business response patterns (Norma's style)
        business_patterns = ['good afternoon', 'good morning', 'thanks for reaching', 
                           'thanks so much', "we'd be glad", 'talk soon', 'norma']
        business_matches = sum(1 for pattern in business_patterns if pattern in text_lower)
        
        # Customer inquiry patterns
        inquiry_patterns = ['name:', 'lead created:', 'what kind of', 'how many stories']
        inquiry_matches = sum(1 for pattern in inquiry_patterns if pattern in text_lower)
        
        if business_matches >= 2:
            logger.info(f"[VECTOR-PDF] ‚úÖ BUSINESS RESPONSE ({business_matches} matches)")
            return 'response'
        elif inquiry_matches >= 2:
            logger.info(f"[VECTOR-PDF] ‚úÖ CUSTOMER INQUIRY ({inquiry_matches} matches)")
            return 'inquiry'
        elif business_matches > 0:
            return 'response'
        elif inquiry_matches > 0:
            return 'inquiry'
        else:
            return 'general'
    
    def _count_tokens(self, text: str) -> int:
        """–ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —Ç–æ–∫–µ–Ω—ñ–≤"""
        if not self.encoding:
            return len(text) // 4
        return len(self.encoding.encode(text))
    
    def generate_embeddings(self, chunks: List[DocumentChunk]) -> List[Tuple[DocumentChunk, List[float]]]:
        """–ì–µ–Ω–µ—Ä—É—î OpenAI –µ–º–±–µ–¥—ñ–Ω–≥–∏"""
        if not self.openai_client:
            raise ValueError("OpenAI client not initialized")
        
        logger.info(f"[VECTOR-PDF] Generating embeddings for {len(chunks)} chunks")
        
        embeddings_data = []
        
        try:
            texts = [chunk.content for chunk in chunks]
            
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=texts,
                dimensions=1536
            )
            
            for chunk, embedding_obj in zip(chunks, response.data):
                embeddings_data.append((chunk, embedding_obj.embedding))
            
            logger.info(f"[VECTOR-PDF] Generated {len(embeddings_data)} embeddings")
            return embeddings_data
            
        except Exception as e:
            logger.error(f"[VECTOR-PDF] Error generating embeddings: {e}")
            raise
    
    def calculate_file_hash(self, file_content: bytes) -> str:
        """–†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Ö–µ—à —Ñ–∞–π–ª—É"""
        return hashlib.sha256(file_content).hexdigest()
    
    def process_pdf_file(
        self, 
        file_content: bytes, 
        filename: str, 
        business_id: str,
        location_id: Optional[str] = None
    ) -> Dict:
        """–ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –æ–±—Ä–æ–±–∫–∏ PDF"""
        
        logger.info(f"[VECTOR-PDF] ======== PROCESSING PDF ========")
        logger.info(f"[VECTOR-PDF] File: {filename}")
        logger.info(f"[VECTOR-PDF] Business: {business_id}")
        
        try:
            # –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
            if b'%PDF' in file_content[:100] or filename.lower().endswith('.pdf'):
                pdf_result = self.extract_text_from_pdf_bytes(file_content, filename)
                
                if not pdf_result['success']:
                    raise ValueError("Failed to extract text from PDF")
                
                all_text = pdf_result['text']
                page_count = len(pdf_result['pages'])
            else:
                all_text = file_content.decode('utf-8', errors='ignore')
                page_count = 1
            
            if not all_text.strip():
                raise ValueError("No text content found")
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —á–∞–Ω–∫—ñ–≤
            chunks = self.create_semantic_chunks(all_text)
            
            if not chunks:
                raise ValueError("No chunks created")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤
            embeddings_data = self.generate_embeddings(chunks)
            
            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ë–î
            from .vector_models import VectorDocument, VectorChunk
            
            with transaction.atomic():
                file_hash = self.calculate_file_hash(file_content)
                
                document = VectorDocument.objects.create(
                    business_id=business_id,
                    location_id=location_id,
                    filename=filename,
                    file_hash=file_hash,
                    file_size=len(file_content),
                    page_count=page_count,
                    chunk_count=len(chunks),
                    total_tokens=sum(chunk.token_count for chunk in chunks),
                    processing_status='completed',
                    embedding_model='text-embedding-3-small',
                    embedding_dimensions=1536,
                    metadata={
                        'chunks_by_type': {
                            chunk_type: len([c for c in chunks if c.chunk_type == chunk_type])
                            for chunk_type in set(chunk.chunk_type for chunk in chunks)
                        }
                    }
                )
                
                # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —á–∞–Ω–∫—ñ–≤
                chunk_objects = []
                for chunk, embedding in embeddings_data:
                    chunk_obj = VectorChunk(
                        document=document,
                        content=chunk.content,
                        page_number=chunk.page_number,
                        chunk_index=chunk.chunk_index,
                        token_count=chunk.token_count,
                        embedding=embedding,
                        chunk_type=chunk.chunk_type,
                        metadata=chunk.metadata
                    )
                    chunk_objects.append(chunk_obj)
                
                VectorChunk.objects.bulk_create(chunk_objects)
                
                logger.info(f"[VECTOR-PDF] ‚úÖ SUCCESS: {len(chunk_objects)} chunks saved")
                logger.info(f"[VECTOR-PDF] Types: {document.metadata['chunks_by_type']}")
            
            return {
                'document_id': document.id,
                'chunks_count': len(chunk_objects),
                'chunk_types': document.metadata['chunks_by_type']
            }
            
        except Exception as e:
            logger.error(f"[VECTOR-PDF] Error: {e}")
            raise


# –ì–ª–æ–±–∞–ª—å–Ω–∞ –∑–º—ñ–Ω–Ω–∞ (–í–ê–ñ–õ–ò–í–û!)
vector_pdf_service = VectorPDFService()
simple_pdf_service = vector_pdf_service  # Legacy compatibility
