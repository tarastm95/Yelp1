"""
üîó API Views for Sample Replies Management (–†–µ–∂–∏–º 2: AI Generated)
–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ Sample Replies –¥–ª—è AI –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
"""

import logging
from django.http import JsonResponse
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.parsers import MultiPartParser, FormParser
from .models import AutoResponseSettings, YelpBusiness
from .vector_pdf_service import vector_pdf_service
from .vector_search_service import vector_search_service

logger = logging.getLogger(__name__)

class SampleRepliesFileUploadView(APIView):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è PDF/text —Ñ–∞–π–ª—É –∑ Sample Replies (–†–µ–∂–∏–º 2: AI Generated)"""
    
    parser_classes = [MultiPartParser, FormParser]
    
    def post(self, request):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ç–∞ –æ–±—Ä–æ–±–∏—Ç–∏ —Ñ–∞–π–ª"""
        
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logger.info(f"[SAMPLE-REPLIES-API] ========== FILE UPLOAD STARTED [{timestamp}] ==========")
        logger.info(f"[SAMPLE-REPLIES-API] üöÄ MODE 2: AI Generated - Vector Processing")
        
        try:
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤
            business_id = request.data.get('business_id')
            phone_available = request.data.get('phone_available', 'false').lower() == 'true'
            uploaded_file = request.FILES.get('file')
            
            if not business_id:
                return Response({
                    'error': 'business_id is required'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            if not uploaded_file:
                return Response({
                    'error': 'file is required'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            logger.info(f"[SAMPLE-REPLIES-API] Processing file: {uploaded_file.name}")
            logger.info(f"[SAMPLE-REPLIES-API] File size: {uploaded_file.size} bytes ({uploaded_file.size / (1024*1024):.2f} MB)")
            logger.info(f"[SAMPLE-REPLIES-API] File type: {uploaded_file.content_type}")
            logger.info(f"[SAMPLE-REPLIES-API] Business: {business_id}")
            logger.info(f"[SAMPLE-REPLIES-API] Phone Available: {phone_available}")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ –ø–æ—Ç–æ—á–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –±—ñ–∑–Ω–µ—Å—É –ü–ï–†–ï–î –æ–±—Ä–æ–±–∫–æ—é
            existing_settings = AutoResponseSettings.objects.filter(
                business__business_id=business_id,
                phone_available=phone_available
            ).first()
            
            if existing_settings:
                logger.info(f"[SAMPLE-REPLIES-API] üìã Existing settings found:")
                logger.info(f"[SAMPLE-REPLIES-API]   - AI mode: {existing_settings.use_ai_greeting}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Sample replies: {existing_settings.use_sample_replies}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Current filename: {existing_settings.sample_replies_filename}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Content length: {len(existing_settings.sample_replies_content or '')}")
            else:
                logger.info(f"[SAMPLE-REPLIES-API] üìã No existing settings found - will create new ones")
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –±—ñ–∑–Ω–µ—Å—É
            try:
                business = YelpBusiness.objects.get(business_id=business_id)
                logger.info(f"[SAMPLE-REPLIES-API] Found business: {business.name}")
            except YelpBusiness.DoesNotExist:
                return Response({
                    'error': f'Business {business_id} not found'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É —Ñ–∞–π–ª—É (–º–∞–∫—Å–∏–º—É–º 5MB)
            max_size = 5 * 1024 * 1024  # 5MB
            if uploaded_file.size > max_size:
                return Response({
                    'error': 'File too large',
                    'message': f'Maximum file size is {max_size // (1024*1024)}MB'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # üîç VECTOR PROCESSING: –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—É –∑ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–º —á–∞–Ω–∫—É–≤–∞–Ω–Ω—è–º —Ç–∞ –µ–º–±–µ–¥—ñ–Ω–≥–∞–º–∏
            file_content = uploaded_file.read()
            
            # –°–ø—Ä–æ–±–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
            try:
                logger.info(f"[SAMPLE-REPLIES-API] üîç Starting vector processing...")
                
                # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±—Ä–æ–±–∫–∞ PDF –∑ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—î—é
                from asgiref.sync import async_to_sync
                process_pdf_sync = async_to_sync(vector_pdf_service.process_pdf_file)
                processing_result = process_pdf_sync(
                    file_content=file_content,
                    filename=uploaded_file.name,
                    business_id=business_id,
                    location_id=None  # TODO: Add location support
                )
                
                logger.info(f"[SAMPLE-REPLIES-API] ‚úÖ Vector processing completed:")
                logger.info(f"[SAMPLE-REPLIES-API] - Document ID: {processing_result['document_id']}")
                logger.info(f"[SAMPLE-REPLIES-API] - Chunks: {processing_result['chunks_count']}")
                logger.info(f"[SAMPLE-REPLIES-API] - Pages: {processing_result['pages_count']}")
                logger.info(f"[SAMPLE-REPLIES-API] - Tokens: {processing_result['total_tokens']}")
                logger.info(f"[SAMPLE-REPLIES-API] - Chunk types: {processing_result['chunk_types']}")
                
                # –û–Ω–æ–≤–ª–µ–Ω–Ω—è AutoResponseSettings –¥–ª—è backward compatibility
                logger.info(f"[SAMPLE-REPLIES-API] üîß Creating/updating AutoResponseSettings...")
                auto_settings, created = AutoResponseSettings.objects.get_or_create(
                    business=business,
                    phone_available=phone_available,
                    defaults={
                        'enabled': True,
                        'use_ai_greeting': True  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —É–≤—ñ–º–∫–Ω—É—Ç–∏ AI —Ä–µ–∂–∏–º
                    }
                )
                
                logger.info(f"[SAMPLE-REPLIES-API] üìã AutoResponseSettings result:")
                logger.info(f"[SAMPLE-REPLIES-API]   - Created new: {created}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Settings ID: {auto_settings.id}")
                logger.info(f"[SAMPLE-REPLIES-API]   - AI mode: {auto_settings.use_ai_greeting}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Enabled: {auto_settings.enabled}")
                
                # –ü–µ—Ä–µ–∫–æ–Ω–∞—î–º–æ—Å—è —â–æ AI —Ä–µ–∂–∏–º —É–≤—ñ–º–∫–Ω–µ–Ω–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
                if not auto_settings.use_ai_greeting:
                    logger.warning(f"[SAMPLE-REPLIES-API] ‚ö†Ô∏è AI mode was disabled, enabling for vector processing...")
                    auto_settings.use_ai_greeting = True
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –±–∞–∑–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é (–¥–ª—è fallback)
                auto_settings.sample_replies_filename = uploaded_file.name
                auto_settings.use_sample_replies = True  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —É–≤—ñ–º–∫–Ω—É—Ç–∏
                # sample_replies_content –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è –ø–æ—Ä–æ–∂–Ω—ñ–º - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫
                auto_settings.save()
                
                logger.info(f"[SAMPLE-REPLIES-API] üíæ Settings saved successfully:")
                logger.info(f"[SAMPLE-REPLIES-API]   - Final AI mode: {auto_settings.use_ai_greeting}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Final sample replies: {auto_settings.use_sample_replies}")
                logger.info(f"[SAMPLE-REPLIES-API]   - Filename stored: {auto_settings.sample_replies_filename}")
                
                logger.info(f"[SAMPLE-REPLIES-API] ‚úÖ VECTOR PROCESSING SUCCESS!")
                logger.info(f"[SAMPLE-REPLIES-API] üéâ File '{uploaded_file.name}' processed with {processing_result['chunks_count']} chunks")
                
                return Response({
                    'message': 'Sample replies uploaded and processed with vector embeddings successfully',
                    'filename': uploaded_file.name,
                    'document_id': processing_result['document_id'],
                    'chunks_count': processing_result['chunks_count'],
                    'pages_count': processing_result['pages_count'],
                    'total_tokens': processing_result['total_tokens'],
                    'chunk_types': processing_result['chunk_types'],
                    'mode': 'AI Generated (Mode 2) - Vector Enhanced',
                    'vector_search_enabled': True,
                    'auto_enabled': True
                }, status=status.HTTP_201_CREATED)
                
            except Exception as vector_error:
                logger.error(f"[SAMPLE-REPLIES-API] ‚ùå VECTOR PROCESSING FAILED!")
                logger.error(f"[SAMPLE-REPLIES-API] Error type: {type(vector_error).__name__}")
                logger.error(f"[SAMPLE-REPLIES-API] Error message: {vector_error}")
                logger.error(f"[SAMPLE-REPLIES-API] File details: {uploaded_file.name}, {uploaded_file.size} bytes")
                logger.exception("[SAMPLE-REPLIES-API] Full error traceback:")
                logger.warning("[SAMPLE-REPLIES-API] üîÑ Falling back to simple text processing...")
                
                # üìÑ FALLBACK: –ü—Ä–æ—Å—Ç–∏–π –ø–∞—Ä—Å–∏–Ω–≥ —è–∫—â–æ –≤–µ–∫—Ç–æ—Ä–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –Ω–µ –≤–¥–∞–ª–∞—Å—è
                extracted_text = vector_pdf_service.extract_text_from_uploaded_file(
                    file_content, uploaded_file.name
                )
                
                # –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥—É
                if extracted_text in ["PDF_BINARY_DETECTED", "PDF_BINARY_DETECTED_NO_PARSER"]:
                    return Response({
                        'error': 'PDF binary detected',
                        'message': 'Binary PDF files require additional libraries. Please copy text from PDF and use "Paste Text" option instead.',
                        'instruction': 'Open your PDF, select all text (Ctrl+A), copy (Ctrl+C), and paste into the text area.',
                        'vector_processing_failed': True
                    }, status=status.HTTP_400_BAD_REQUEST)
                
                if extracted_text == "EMPTY_FILE":
                    return Response({
                        'error': 'Empty file',
                        'message': 'The uploaded file appears to be empty.'
                    }, status=status.HTTP_400_BAD_REQUEST)
                
                if extracted_text in ["ENCODING_ERROR", "PROCESSING_ERROR"]:
                    return Response({
                        'error': 'Processing error',
                        'message': 'Failed to process file. Please try copying and pasting the text content instead.'
                    }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
                
                # –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–Ω—Ç–µ–Ω—Ç—É
                formatted_content = vector_pdf_service.format_sample_replies(extracted_text)
                
                if formatted_content == "EMPTY_CONTENT":
                    return Response({
                        'error': 'Empty content',
                        'message': 'File content is empty after processing.'
                    }, status=status.HTTP_400_BAD_REQUEST)
                
                # –í–∞–ª—ñ–¥–∞—Ü—ñ—è Sample Replies –∫–æ–Ω—Ç–µ–Ω—Ç—É
                is_valid, validation_error = vector_pdf_service.validate_sample_replies_content(formatted_content)
                
                if not is_valid:
                    return Response({
                        'error': 'Invalid content',
                        'message': validation_error
                    }, status=status.HTTP_400_BAD_REQUEST)
                
                # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ fallback –º–µ—Ç–æ–¥
                auto_settings, created = AutoResponseSettings.objects.get_or_create(
                    business=business,
                    phone_available=phone_available,
                    defaults={
                        'enabled': True,
                        'use_ai_greeting': True
                    }
                )
                
                auto_settings.sample_replies_content = formatted_content  # Legacy fallback
                auto_settings.sample_replies_filename = uploaded_file.name
                auto_settings.use_sample_replies = True
                auto_settings.save()
                
                logger.warning(f"[SAMPLE-REPLIES-API] ‚ö†Ô∏è FALLBACK MODE SUCCESS:")
                logger.warning(f"[SAMPLE-REPLIES-API]   - File stored in legacy mode: {uploaded_file.name}")
                logger.warning(f"[SAMPLE-REPLIES-API]   - Content length: {len(formatted_content)} characters")
                logger.warning(f"[SAMPLE-REPLIES-API]   - AI mode: {auto_settings.use_ai_greeting}")
                logger.warning(f"[SAMPLE-REPLIES-API]   - Vector search: DISABLED due to processing failure")
                
                return Response({
                    'message': 'Sample replies uploaded (fallback mode - vector processing failed)',
                    'filename': uploaded_file.name,
                    'content_length': len(formatted_content),
                    'preview': formatted_content[:300] + '...' if len(formatted_content) > 300 else formatted_content,
                    'mode': 'AI Generated (Mode 2) - Legacy Fallback',
                    'vector_search_enabled': False,
                    'vector_error': str(vector_error)
                }, status=status.HTTP_201_CREATED)
            
        except Exception as e:
            logger.error(f"[SAMPLE-REPLIES-API] üî• CRITICAL UPLOAD ERROR!")
            logger.error(f"[SAMPLE-REPLIES-API] Error type: {type(e).__name__}")
            logger.error(f"[SAMPLE-REPLIES-API] Error message: {e}")
            if 'uploaded_file' in locals():
                logger.error(f"[SAMPLE-REPLIES-API] File context: {uploaded_file.name if uploaded_file else 'N/A'}")
            if 'business_id' in locals():
                logger.error(f"[SAMPLE-REPLIES-API] Business context: {business_id}")
            logger.exception("[SAMPLE-REPLIES-API] Full error traceback:")
            
            return Response({
                'error': 'Upload failed',
                'details': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class SampleRepliesTextSaveView(APIView):
    """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è Sample Replies —è–∫ —Ç–µ–∫—Å—Ç (—Ä—É—á–Ω–∏–π –≤–≤—ñ–¥) –¥–ª—è —Ä–µ–∂–∏–º—É AI Generated"""
    
    def post(self, request):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ Sample Replies —Ç–µ–∫—Å—Ç"""
        
        logger.info("[SAMPLE-REPLIES-API] ========== TEXT SAVE (Mode 2: AI Generated) ==========")
        
        try:
            business_id = request.data.get('business_id')
            phone_available = request.data.get('phone_available', 'false').lower() == 'true'
            sample_text = request.data.get('sample_text', '').strip()
            
            logger.info(f"[SAMPLE-REPLIES-API] Business: {business_id}")
            logger.info(f"[SAMPLE-REPLIES-API] Phone Available: {phone_available}")
            logger.info(f"[SAMPLE-REPLIES-API] Text length: {len(sample_text)} chars")
            
            if not business_id or not sample_text:
                return Response({
                    'error': 'business_id and sample_text are required'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –±—ñ–∑–Ω–µ—Å—É
            try:
                business = YelpBusiness.objects.get(business_id=business_id)
                logger.info(f"[SAMPLE-REPLIES-API] Found business: {business.name}")
            except YelpBusiness.DoesNotExist:
                return Response({
                    'error': f'Business {business_id} not found'
                }, status=status.HTTP_404_NOT_FOUND)
            
            # üîç VECTOR PROCESSING: –û–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç—É –∑ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–º —á–∞–Ω–∫—É–≤–∞–Ω–Ω—è–º —Ç–∞ –µ–º–±–µ–¥—ñ–Ω–≥–∞–º–∏
            
            # –°–ø—Ä–æ–±–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
            try:
                logger.info(f"[SAMPLE-REPLIES-API] üîç Starting vector processing for text input...")
                
                # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç—É –∑ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—î—é
                from asgiref.sync import async_to_sync
                process_pdf_sync = async_to_sync(vector_pdf_service.process_pdf_file)
                processing_result = process_pdf_sync(
                    file_content=sample_text.encode('utf-8'),
                    filename="Manual_Text_Input.txt",
                    business_id=business_id,
                    location_id=None
                )
                
                logger.info(f"[SAMPLE-REPLIES-API] ‚úÖ Vector processing completed for text input:")
                logger.info(f"[SAMPLE-REPLIES-API] - Document ID: {processing_result['document_id']}")
                logger.info(f"[SAMPLE-REPLIES-API] - Chunks: {processing_result['chunks_count']}")
                logger.info(f"[SAMPLE-REPLIES-API] - Tokens: {processing_result['total_tokens']}")
                
                # –û–Ω–æ–≤–ª–µ–Ω–Ω—è AutoResponseSettings
                auto_settings, created = AutoResponseSettings.objects.get_or_create(
                    business=business,
                    phone_available=phone_available,
                    defaults={
                        'enabled': True,
                        'use_ai_greeting': True
                    }
                )
                
                auto_settings.sample_replies_filename = "Manual Text Input (Vector Enhanced)"
                auto_settings.use_sample_replies = True
                # sample_replies_content –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è –ø–æ—Ä–æ–∂–Ω—ñ–º - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫
                auto_settings.save()
                
                return Response({
                    'message': 'Sample replies text processed with vector embeddings successfully',
                    'document_id': processing_result['document_id'],
                    'chunks_count': processing_result['chunks_count'],
                    'total_tokens': processing_result['total_tokens'],
                    'chunk_types': processing_result['chunk_types'],
                    'mode': 'AI Generated (Mode 2) - Vector Enhanced',
                    'vector_search_enabled': True,
                    'source': 'Manual Input'
                })
                
            except Exception as vector_error:
                logger.error(f"[SAMPLE-REPLIES-API] Vector processing failed for text: {vector_error}")
                logger.warning("[SAMPLE-REPLIES-API] Falling back to simple text processing...")
                
                # üìÑ FALLBACK: –ü—Ä–æ—Å—Ç–∏–π –ø–∞—Ä—Å–∏–Ω–≥ —è–∫—â–æ –≤–µ–∫—Ç–æ—Ä–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –Ω–µ –≤–¥–∞–ª–∞—Å—è
                formatted_content = vector_pdf_service.format_sample_replies(sample_text)
                
                if formatted_content == "EMPTY_CONTENT":
                    return Response({
                        'error': 'Empty content',
                        'message': 'Text content is empty after processing.'
                    }, status=status.HTTP_400_BAD_REQUEST)
                
                # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–Ω—Ç–µ–Ω—Ç—É
                is_valid, validation_error = vector_pdf_service.validate_sample_replies_content(formatted_content)
                
                if not is_valid:
                    return Response({
                        'error': 'Invalid content',
                        'message': validation_error
                    }, status=status.HTTP_400_BAD_REQUEST)
                
                # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ fallback –º–µ—Ç–æ–¥
                auto_settings, created = AutoResponseSettings.objects.get_or_create(
                    business=business,
                    phone_available=phone_available,
                    defaults={
                        'enabled': True,
                        'use_ai_greeting': True
                    }
                )
                
                auto_settings.sample_replies_content = formatted_content  # Legacy fallback
                auto_settings.sample_replies_filename = "Manual Text Input (Legacy)"
                auto_settings.use_sample_replies = True
                auto_settings.save()
                
                return Response({
                    'message': 'Sample replies text saved (fallback mode - vector processing failed)',
                    'content_length': len(formatted_content),
                    'preview': formatted_content[:300] + '...' if len(formatted_content) > 300 else formatted_content,
                    'mode': 'AI Generated (Mode 2) - Legacy Fallback',
                    'vector_search_enabled': False,
                    'vector_error': str(vector_error),
                    'source': 'Manual Input'
                })
            
        except Exception as e:
            logger.error(f"[SAMPLE-REPLIES-API] Text save error: {e}")
            logger.exception("Text save error details")
            return Response({
                'error': 'Save failed',
                'details': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class SampleRepliesStatusView(APIView):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å Sample Replies –¥–ª—è –±—ñ–∑–Ω–µ—Å—É"""
    
    def get(self, request):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å Sample Replies"""
        
        logger.info(f"[SAMPLE-REPLIES-STATUS] ========== STATUS CHECK REQUEST ==========")
        
        business_id = request.GET.get('business_id')
        phone_available = request.GET.get('phone_available', 'false').lower() == 'true'
        
        logger.info(f"[SAMPLE-REPLIES-STATUS] Business ID: {business_id}")
        logger.info(f"[SAMPLE-REPLIES-STATUS] Phone Available: {phone_available}")
        
        if not business_id:
            logger.error(f"[SAMPLE-REPLIES-STATUS] ‚ùå Missing business_id parameter")
            return Response({
                'error': 'business_id parameter is required'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            business = YelpBusiness.objects.get(business_id=business_id)
            logger.info(f"[SAMPLE-REPLIES-STATUS] ‚úÖ Business found: {business.name}")
        except YelpBusiness.DoesNotExist:
            logger.error(f"[SAMPLE-REPLIES-STATUS] ‚ùå Business not found: {business_id}")
            return Response({
                'error': f'Business {business_id} not found'
            }, status=status.HTTP_404_NOT_FOUND)
        
        try:
            auto_settings = AutoResponseSettings.objects.get(
                business=business,
                phone_available=phone_available
            )
            
            logger.info(f"[SAMPLE-REPLIES-STATUS] üìã AutoResponseSettings found:")
            logger.info(f"[SAMPLE-REPLIES-STATUS]   - AI mode: {auto_settings.use_ai_greeting}")
            logger.info(f"[SAMPLE-REPLIES-STATUS]   - Use sample replies: {auto_settings.use_sample_replies}")
            logger.info(f"[SAMPLE-REPLIES-STATUS]   - Filename: {auto_settings.sample_replies_filename}")
            logger.info(f"[SAMPLE-REPLIES-STATUS]   - Content length: {len(auto_settings.sample_replies_content or '')}")
            
            has_sample_replies = bool(
                auto_settings.use_sample_replies and 
                auto_settings.sample_replies_content
            )
            
            # üîç –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ vector –¥–æ–∫—É–º–µ–Ω—Ç–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å—É
            logger.info(f"[SAMPLE-REPLIES-STATUS] üîç Checking vector documents...")
            from .vector_models import VectorDocument, VectorChunk
            
            vector_documents = VectorDocument.objects.filter(
                business_id=business_id
            ).order_by('-created_at')
            
            vector_status = {
                'total_documents': vector_documents.count(),
                'completed_documents': vector_documents.filter(processing_status='completed').count(),
                'processing_documents': vector_documents.filter(processing_status='processing').count(),
                'error_documents': vector_documents.filter(processing_status='error').count(),
                'total_chunks': VectorChunk.objects.filter(document__business_id=business_id).count(),
                'documents': []
            }
            
            # –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∫–æ–∂–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç
            for doc in vector_documents[:10]:  # –û—Å—Ç–∞–Ω–Ω—ñ 10 –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
                chunks_count = doc.chunks.count()
                vector_status['documents'].append({
                    'id': doc.id,
                    'filename': doc.filename,
                    'status': doc.processing_status,
                    'chunks_count': chunks_count,
                    'page_count': doc.page_count,
                    'total_tokens': doc.total_tokens,
                    'file_size': doc.file_size,
                    'created_at': doc.created_at.isoformat(),
                    'updated_at': doc.updated_at.isoformat(),
                    'error_message': doc.error_message,
                    'embedding_model': doc.embedding_model,
                    'has_vector_data': chunks_count > 0
                })
            
            return Response({
                'business_name': business.name,
                'has_sample_replies': has_sample_replies,
                'use_sample_replies': auto_settings.use_sample_replies,
                'filename': auto_settings.sample_replies_filename,
                'content_length': len(auto_settings.sample_replies_content) if auto_settings.sample_replies_content else 0,
                'priority': auto_settings.sample_replies_priority,
                'ai_mode_enabled': auto_settings.use_ai_greeting,
                'mode': 'AI Generated (Mode 2)' if auto_settings.use_ai_greeting else 'Template (Mode 1)',
                'vector_status': vector_status,
                'vector_search_available': vector_status['total_chunks'] > 0
            })
            
        except AutoResponseSettings.DoesNotExist:
            # üîç –ù–∞–≤—ñ—Ç—å —è–∫—â–æ –Ω–µ–º–∞—î –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å, –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ vector –¥–æ–∫—É–º–µ–Ω—Ç–∏
            from .vector_models import VectorDocument, VectorChunk
            
            vector_documents = VectorDocument.objects.filter(
                business_id=business_id
            ).order_by('-created_at')
            
            vector_status = {
                'total_documents': vector_documents.count(),
                'completed_documents': vector_documents.filter(processing_status='completed').count(),
                'processing_documents': vector_documents.filter(processing_status='processing').count(),
                'error_documents': vector_documents.filter(processing_status='error').count(),
                'total_chunks': VectorChunk.objects.filter(document__business_id=business_id).count(),
                'documents': []
            }
            
            # –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∫–æ–∂–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç
            for doc in vector_documents[:10]:
                chunks_count = doc.chunks.count()
                vector_status['documents'].append({
                    'id': doc.id,
                    'filename': doc.filename,
                    'status': doc.processing_status,
                    'chunks_count': chunks_count,
                    'page_count': doc.page_count,
                    'total_tokens': doc.total_tokens,
                    'file_size': doc.file_size,
                    'created_at': doc.created_at.isoformat(),
                    'updated_at': doc.updated_at.isoformat(),
                    'error_message': doc.error_message,
                    'embedding_model': doc.embedding_model,
                    'has_vector_data': chunks_count > 0
                })
            
            return Response({
                'business_name': business.name,
                'has_sample_replies': False,
                'use_sample_replies': False,
                'filename': None,
                'content_length': 0,
                'priority': True,
                'ai_mode_enabled': False,
                'mode': 'Not configured',
                'vector_status': vector_status,
                'vector_search_available': vector_status['total_chunks'] > 0
            })


class VectorSearchTestView(APIView):
    """–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    
    def post(self, request):
        """–í–∏–∫–æ–Ω–∞—Ç–∏ —Ç–µ—Å—Ç–æ–≤–∏–π –≤–µ–∫—Ç–æ—Ä–Ω–∏–π –ø–æ—à—É–∫"""
        
        try:
            business_id = request.data.get('business_id')
            test_query = request.data.get('test_query', 'roof repair service inquiry')
            location_id = request.data.get('location_id', None)
            
            if not business_id:
                return Response({
                    'error': 'business_id is required'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            logger.info(f"[VECTOR-TEST-API] Testing vector search for business {business_id}")
            
            # –í–∏–∫–æ–Ω–∞–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ—à—É–∫—É
            test_result = vector_search_service.test_vector_search(
                business_id=business_id,
                test_query=test_query,
                location_id=location_id
            )
            
            return Response(test_result)
            
        except Exception as e:
            logger.error(f"[VECTOR-TEST-API] Test error: {e}")
            return Response({
                'success': False,
                'error': 'Test failed',
                'details': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class VectorChunkListView(APIView):
    """–°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö —á–∞–Ω–∫—ñ–≤ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    
    def get(self, request):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫—ñ–≤"""
        
        business_id = request.GET.get('business_id')
        location_id = request.GET.get('location_id', None)
        chunk_type = request.GET.get('chunk_type', None)
        limit = min(int(request.GET.get('limit', 10)), 50)
        
        if not business_id:
            return Response({
                'error': 'business_id parameter is required'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            from .vector_models import VectorDocument, VectorChunk
            from django.db.models import Q
            
            # –§—ñ–ª—å—Ç—Ä–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
            doc_filter = Q(business_id=business_id, processing_status='completed')
            if location_id:
                doc_filter &= Q(location_id=location_id)
            
            documents = VectorDocument.objects.filter(doc_filter)
            
            if not documents.exists():
                return Response({
                    'chunks': [],
                    'total': 0,
                    'message': 'No vector documents found for this business'
                })
            
            # –§—ñ–ª—å—Ç—Ä–∏ —á–∞–Ω–∫—ñ–≤
            chunk_filter = Q(document__in=documents)
            if chunk_type:
                chunk_filter &= Q(chunk_type=chunk_type)
            
            chunks = VectorChunk.objects.filter(chunk_filter).select_related('document')[:limit]
            
            chunks_data = []
            for chunk in chunks:
                chunks_data.append({
                    'id': chunk.id,
                    'content': chunk.get_preview(200),
                    'full_content': chunk.content,
                    'page_number': chunk.page_number,
                    'chunk_index': chunk.chunk_index,
                    'token_count': chunk.token_count,
                    'chunk_type': chunk.chunk_type,
                    'metadata': chunk.metadata,
                    'document_filename': chunk.document.filename,
                    'created_at': chunk.created_at.isoformat(),
                    'has_embedding': chunk.similarity_search_ready
                })
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = vector_search_service.get_chunk_statistics(business_id, location_id)
            
            return Response({
                'chunks': chunks_data,
                'total': len(chunks_data),
                'limit': limit,
                'statistics': stats,
                'filters': {
                    'business_id': business_id,
                    'location_id': location_id,
                    'chunk_type': chunk_type
                }
            })
            
        except Exception as e:
            logger.error(f"[VECTOR-CHUNKS-API] Error: {e}")
            return Response({
                'error': 'Failed to load chunks',
                'details': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
