#!/usr/bin/env python3
"""
üîß Fix broken imports and method calls in VectorPDFService
"""

import re

def fix_broken_imports():
    """–í–∏–ø—Ä–∞–≤–ª—è—î –≤—Å—ñ broken –ø–æ—Å–∏–ª–∞–Ω–Ω—è –≤ VectorPDFService"""
    
    with open('backend/webhooks/vector_pdf_service.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 1. –í–∏–¥–∞–ª—è—î–º–æ broken import —Ç–∞ –∑–º—ñ–Ω–Ω—É ADVANCED_PDF_PARSER_AVAILABLE
    old_import = '''# Import the advanced PDF parser
try:
    from .advanced_pdf_parser import advanced_pdf_parser
    ADVANCED_PDF_PARSER_AVAILABLE = True
    logger.info("[VECTOR-PDF] ‚úÖ Advanced PDF Parser loaded")
except ImportError as e:
    ADVANCED_PDF_PARSER_AVAILABLE = False
    logger.warning(f"[VECTOR-PDF] ‚ö†Ô∏è Advanced PDF Parser not available: {e}")'''
    
    # –ü—Ä–æ—Å—Ç–æ –≤–∏–¥–∞–ª—è—î–º–æ —Ü–µ–π –±–ª–æ–∫
    content = content.replace(old_import, '')
    
    # 2. –ó–∞–º—ñ–Ω—é—î–º–æ –º–µ—Ç–æ–¥ extract_text_from_pdf_bytes –Ω–∞ –ø—Ä–æ—Å—Ç–∏–π
    old_method = '''    def extract_text_from_pdf_bytes(self, pdf_bytes: bytes, filename: str) -> Dict:
        """üöÄ Professional PDF extraction using advanced parser"""
        
        if ADVANCED_PDF_PARSER_AVAILABLE:
            logger.info(f"[VECTOR-PDF] üöÄ Using Advanced PDF Parser for: {filename}")
            
            try:
                result = advanced_pdf_parser.extract_text_from_pdf_bytes(pdf_bytes, filename)
                
                if result['success']:
                    logger.info(f"[VECTOR-PDF] ‚úÖ Advanced parser success!")
                    logger.info(f"[VECTOR-PDF] Parser used: {result['parser_used']}")
                    logger.info(f"[VECTOR-PDF] Structure preserved: {result['structure_preserved']}")
                    logger.info(f"[VECTOR-PDF] Sections detected: {len(result['sections_detected'])}")
                    
                    for section in result['sections_detected']:
                        logger.info(f"[VECTOR-PDF]   üìã {section}")
                    
                    return result
                else:
                    logger.warning(f"[VECTOR-PDF] ‚ö†Ô∏è Advanced parser failed, falling back to basic method")
                    for error in result['errors']:
                        logger.warning(f"[VECTOR-PDF]   - {error}")
                        
            except Exception as e:
                logger.error(f"[VECTOR-PDF] ‚ùå Advanced parser exception: {e}")
        
        # Fallback to old method
        logger.info(f"[VECTOR-PDF] üîÑ Using fallback PDF extraction")
        return self._extract_text_fallback(pdf_bytes, filename)'''
    
    new_method = '''    def extract_text_from_pdf_bytes(self, pdf_bytes: bytes, filename: str) -> Dict:
        """üìÑ Simple PDF extraction using PyMuPDF"""
        
        logger.info(f"[VECTOR-PDF] üìÑ Extracting text from PDF: {filename}")
        
        if not PDF_PROCESSING_AVAILABLE:
            raise ValueError("PDF processing libraries not available.")
        
        try:
            doc = fitz.open("pdf", pdf_bytes)
            pages_data = []
            all_text_parts = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                
                if text.strip():
                    pages_data.append({
                        'page_number': page_num + 1,
                        'text': text,
                        'char_count': len(text)
                    })
                    all_text_parts.append(text)
                    
                    logger.info(f"[VECTOR-PDF] Page {page_num + 1}: {len(text)} chars")
            
            doc.close()
            
            all_text = "\\n\\n".join(all_text_parts)
            
            # –ê–Ω–∞–ª—ñ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ PDF
            text_lower = all_text.lower()
            structure_indicators = {
                'inquiry_information': 'inquiry information:' in text_lower,
                'response_marker': 'response:' in text_lower,
                'example_marker': 'example #' in text_lower,
                'customer_names': len(re.findall(r'name:\\s*[a-z]+ [a-z]\\.?', text_lower)),
                'norma_signatures': len(re.findall(r'talk soon,?\\s*norma', text_lower, re.IGNORECASE))
            }
            
            logger.info(f"[VECTOR-PDF] üìä PDF Structure Analysis:")
            logger.info(f"[VECTOR-PDF]   Text length: {len(all_text)} chars")
            logger.info(f"[VECTOR-PDF]   Pages extracted: {len(pages_data)}")
            for key, value in structure_indicators.items():
                logger.info(f"[VECTOR-PDF]   {key}: {value}")
            
            return {
                'success': True,
                'text': all_text,
                'pages': pages_data,
                'parser_used': 'pymupdf',
                'structure_preserved': True,
                'sections_detected': [f"{k}: {v}" for k, v in structure_indicators.items() if v],
                'structure_quality_score': sum(1 for v in structure_indicators.values() if v)
            }
            
        except Exception as e:
            logger.error(f"[VECTOR-PDF] PDF extraction error: {e}")
            return {
                'success': False,
                'text': '',
                'pages': [],
                'parser_used': None,
                'structure_preserved': False,
                'sections_detected': [],
                'errors': [str(e)]
            }'''
    
    content = content.replace(old_method, new_method)
    
    # 3. –í–∏–¥–∞–ª—è—î–º–æ –º–µ—Ç–æ–¥ _extract_text_fallback (–≤—ñ–Ω –¥—É–±–ª—é—î —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å)
    fallback_method_pattern = r'    def _extract_text_fallback\(self, pdf_bytes: bytes, filename: str\) -> Dict:.*?return \{[^}]+\}'
    content = re.sub(fallback_method_pattern, '', content, flags=re.DOTALL)
    
    # 4. –í–∏–ø—Ä–∞–≤–ª—è—î–º–æ –≤–∏–∫–ª–∏–∫ —Å—Ç–∞—Ä–æ–≥–æ –º–µ—Ç–æ–¥—É extract_text_from_pdf
    content = content.replace(
        'pages_data = self.extract_text_from_pdf(full_path)',
        '# Using new extract_text_from_pdf_bytes method instead'
    )
    
    # 5. –í–∏–¥–∞–ª—è—î–º–æ broken –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ sample_replies_chunker
    content = content.replace(
        'sections = sample_replies_chunker.parse_sample_replies_document(text)',
        '# sample_replies_chunker removed - using standard method'
    )
    
    # 6. –í–∏–ø—Ä–∞–≤–ª—è—î–º–æ broken _create_sample_replies_chunks method
    old_sample_method = '''    def _create_sample_replies_chunks(self, text: str, max_tokens: int) -> List[DocumentChunk]:
        """–°—Ç–≤–æ—Ä—é—î chunks –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π Sample Replies chunker"""
        
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π chunker
            sections = sample_replies_chunker.parse_sample_replies_document(text)
            
            if not sections:
                logger.warning("[VECTOR-PDF] ‚ö†Ô∏è Specialized chunker failed, falling back to standard")
                return self._create_standard_chunks(text, max_tokens)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ DocumentChunk –æ–±'—î–∫—Ç–∏
            chunks = []
            chunk_index = 0
            
            for section in sections:
                # Inquiry chunk
                inquiry_chunk = DocumentChunk(
                    content=section.inquiry_text,
                    page_number=1,
                    chunk_index=chunk_index,
                    token_count=self._count_tokens(section.inquiry_text),
                    chunk_type='inquiry',
                    metadata={
                        'example_number': section.example_number,
                        'customer_name': section.customer_name,
                        'service_type': section.service_type,
                        'location': section.location,
                        'chunk_purpose': 'customer_data',
                        'has_inquiry': True,
                        'has_response': False,
                        'specialized_chunking': True
                    }
                )
                chunks.append(inquiry_chunk)
                chunk_index += 1
                
                # Response chunk  
                response_chunk = DocumentChunk(
                    content=section.response_text,
                    page_number=1,
                    chunk_index=chunk_index,
                    token_count=self._count_tokens(section.response_text),
                    chunk_type='response',
                    metadata={
                        'example_number': section.example_number,
                        'customer_name': section.customer_name,
                        'service_type': section.service_type,
                        'location': section.location,
                        'chunk_purpose': 'business_response',
                        'has_inquiry': False,
                        'has_response': True,
                        'specialized_chunking': True,
                        'response_style': section.raw_response[:50] + '...' if len(section.raw_response) > 50 else section.raw_response
                    }
                )
                chunks.append(response_chunk)
                chunk_index += 1
            
            logger.info(f"[VECTOR-PDF] üéâ SPECIALIZED CHUNKING SUCCESS:")
            logger.info(f"[VECTOR-PDF] Created {len(chunks)} specialized chunks from {len(sections)} examples")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            chunk_stats = {}
            for chunk in chunks:
                chunk_stats[chunk.chunk_type] = chunk_stats.get(chunk.chunk_type, 0) + 1
            logger.info(f"[VECTOR-PDF] Chunk distribution: {chunk_stats}")
            
            return chunks
            
        except Exception as e:
            logger.error(f"[VECTOR-PDF] ‚ùå Specialized chunking failed: {e}")
            logger.warning("[VECTOR-PDF] üîÑ Falling back to standard chunking")
            return self._create_standard_chunks(text, max_tokens)'''
    
    new_sample_method = '''    def _create_sample_replies_chunks(self, text: str, max_tokens: int) -> List[DocumentChunk]:
        """üîÑ Fallback: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π chunking –¥–ª—è Sample Replies"""
        
        logger.warning("[VECTOR-PDF] ‚ö†Ô∏è Specialized chunker not available - using enhanced standard method")
        return self._create_standard_chunks(text, max_tokens)'''
    
    content = content.replace(old_sample_method, new_sample_method)
    
    with open('backend/webhooks/vector_pdf_service.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("‚úÖ Fixed all broken imports and method calls!")

if __name__ == '__main__':
    fix_broken_imports()
