#!/usr/bin/env python3
"""
üîß Fix duplicate methods and broken references
"""

import re

def fix_duplicates():
    """–í–∏–ø—Ä–∞–≤–ª—è—î –¥—É–±–ª—ñ–∫–∞—Ç–∏ –º–µ—Ç–æ–¥—ñ–≤ —Ç–∞ broken references"""
    
    with open('backend/webhooks/vector_pdf_service.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 1. –°–ø—Ä–æ—â—É—î–º–æ broken _create_sample_replies_chunks –º–µ—Ç–æ–¥  
    # –ó–∞–º—ñ–Ω—é—î–º–æ –≤–µ—Å—å –±–ª–æ–∫ –Ω–∞ –ø—Ä–æ—Å—Ç–∏–π working –º–µ—Ç–æ–¥
    old_broken_method = '''    def _create_sample_replies_chunks(self, text: str, max_tokens: int) -> List[DocumentChunk]:
        """üéØ Simple AI Extractor-based Sample Replies parsing with Pydantic contracts"""
        
        if not SIMPLE_AI_EXTRACTOR_AVAILABLE:'''
    
    new_simple_method = '''    def _create_sample_replies_chunks(self, text: str, max_tokens: int) -> List[DocumentChunk]:
        """üîÑ Simplified: Uses standard chunking with enhanced classification"""
        
        logger.info("[VECTOR-PDF] üîÑ Using simplified Sample Replies processing")
        return self._create_standard_chunks(text, max_tokens)
    
    def _create_standard_chunks(self, text: str, max_tokens: int) -> List[DocumentChunk]:'''
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –ø–æ—á–∞—Ç–æ–∫ broken –º–µ—Ç–æ–¥—É
    broken_start = content.find(old_broken_method)
    if broken_start != -1:
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∫—ñ–Ω–µ—Ü—å broken –º–µ—Ç–æ–¥—É (–¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ def _create_standard_chunks)
        next_method = content.find('def _create_standard_chunks(self, text: str, max_tokens: int)', broken_start + 100)
        
        if next_method != -1:
            # –í–∏—Ä—ñ–∑–∞—î–º–æ broken –∫–æ–¥
            before_broken = content[:broken_start]
            after_broken = content[next_method:]
            
            # –í—Å—Ç–∞–≤–ª—è—î–º–æ —á–∏—Å—Ç–∏–π –º–µ—Ç–æ–¥
            content = before_broken + new_simple_method + after_broken
    
    # 2. –í–∏–¥–∞–ª—è—î–º–æ –¥—Ä—É–≥–∏–π –¥—É–±–ª—ñ–∫–∞—Ç _identify_chunk_type (–ø—Ä–æ—Å—Ç–∏–π –º–µ—Ç–æ–¥)
    simple_identify_pattern = r'    def _identify_chunk_type\(self, text: str\) -> str:\s*"""–í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç—É —Å–µ–∫—Ü—ñ—ó""".*?return \'general\''
    content = re.sub(simple_identify_pattern, '', content, flags=re.DOTALL)
    
    with open('backend/webhooks/vector_pdf_service.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("‚úÖ Fixed all duplicates and broken references!")
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞
    with open('backend/webhooks/vector_pdf_service.py', 'r', encoding='utf-8') as f:
        check_content = f.read()
    
    identify_count = check_content.count('def _identify_chunk_type')
    create_standard_count = check_content.count('def _create_standard_chunks')
    
    print(f"üìä Methods count after cleanup:")
    print(f"  _identify_chunk_type: {identify_count} (should be 1)")
    print(f"  _create_standard_chunks: {create_standard_count} (should be 1)")

if __name__ == '__main__':
    fix_duplicates()
